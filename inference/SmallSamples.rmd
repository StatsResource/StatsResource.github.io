
Inference Procedures for Small Samples {data-navmenu="Inference Procedures"}
==================================================

Column {.tabset}
-------------------------------------------------


### Small Samples 

<h4> Two Small Samples Case</h4>

*  Previously we have looked at large samples, now we will consider small samples.
*  (For the sake of clarity, I will not use small samples that have a combined sample size of greater than 30.
*  Additionally we require the assumption that both samples have equal variance. This assumption \textbf{must} be tested with another formal hypothesis test. We will revisit this later, and in the mean time, assume that the assumption of equal variance holds.




The key differences between the large sample case and the small sample cases arise in the following steps.

*  The standard error is computed in a different way (see next slide).
*  The degrees of freedom used to compute the critical value is $(n_X-1) + (n_Y - 1)$) or equivalently ($n_X + n_Y - 2$).
*  Also - a formal test of equality of variances is required beforehand (End of Year Exam)


<h4> Videos</h4>
* <a href="https://youtu.be/5DY3j8nw5sg/">	Working With Small Samples	</a>	

### Hypothesis Testing

<h4>Hypothesis Test for the Mean of a Single Sample</h4>

This procedure is used to assess whether the population mean  has a specified value, based on the sample mean. The hypotheses are conventionally written in a form similar to below (here the hypothesized population mean is zero).



There are two hypothesis test for the mean of a single sample.

1. The sample is of a normally-distributed variable for which the population standard deviation ($\sigma$) is known. 
2. The sample is of a normally-distributed variable where σ is estimated by the sample standard deviation (s).
 
In practice, the population standard deviation is rarely known. For this reason, we will consider the second case only in this course.

In most statistical packages, this analysis is performed in the summary statistics functions.

### Student $t$-Distribution

<h4> Student $t$-Distribution <h4>

The $t$ distribution is the appropriate basis for
determining the standardized test statistic when the sampling
distribution of the mean is normally distributed but $s$ is not
known. The sampling distribution can be assumed to be normal
either because the population is normal or because the sample is
large enough to invoke the central limit theorem. \\ The $t$
distribution is required when the sample is small ($n < 30$). For
larger samples, normal approximation can be used. For the critical
value approach, the procedure is identical to that described in
Section 10.3 for the normal distribution, except for the use of $t$
instead of z as the test statistic.


### Independent one-sample $t$-test
In testing the null hypothesis that the population mean is equal to a specified value $\mu_{0}$, one uses the statistic

\[t = \frac{\overline{x} - \mu_0}{s / \sqrt{n}}\]

where $s$ is the sample standard deviation and $n$ is the sample size. The degrees of freedom used in this test is $n - 1$.

### Standards Error

<h4>Two Small Samples Case: Standard Error</h4>

Computing the standard error requires a two step calculation. From the formulae, we have the two equations below. The first term $s_p^2$ is called the ***pooled variance*** of the combined samples.
\[
s_p^2&=&\frac{s_X^2(n_X-1)+s_Y^2(n_Y-1)}{n_X+n_Y-2}.\]
\[
S.E.(\bar{X}-\bar{Y})&=&\sqrt{s_p^2\left(\frac{1}{n_X}+\frac{1}{n_Y}\right)}.
\]

#### Confidence interval of a mean (small sample)

<h5> Confidence interval of a mean (small sample)</h5>

If the data have a normal probability distribution and the sample
standard deviation $s$ is used to estimate the population
standard deviation $\sigma$, the interval estimate is given by:
\[
\bar{X} \pm t_{1-\alpha/2,n-1}\frac{s}{\sqrt{n}}
\]
where $t_{1-\alpha/2,n-1}$ is the value providing an area of $\alpha/2$ in the upper tail of a Student’s t distribution with n - 1 degrees of freedom.


--------------------



#### {Small samples}
 *  We indicated that use of the normal distribution in estimating a population mean is warranted
for any large sample ($n > 30$). *  For a small sample ($n \leq 30$) only if the population is normally distributed
\textbf{and} $\sigma$ is known, the standard normal distribution can be used compute quantiles. In practice,
this case is unusual.
*  Now we consider the situation in which the sample is small and the population is normally distributed,
but $\sigma$ is not known.

<p>

*  Student's $t-$distribution is a variation of the normal distribution, designed to factor in the increased uncertainty resulting from smaller samples.
*  The distribution is really a family of distributions, with
a somewhat different distribution associated with the degrees of freedom ($df$). For a confidence interval for the
population mean based on a sample of size n, $df = n - 1$.


<p>


*  With increasing
sample size, the $t-$distribution approaches the form of the standard normal (`Z') distribution.
*  In fact the standard normal distribution can be thought of as the $t-$distribution with $\infty$ degrees of freedom.
*  For computing quantiles, we will consider the `Z' distribution in this way.
*  For values of $n$ greater then 30, the difference between using $df = n-1$ and $df = \infty$ is negligible.

*  As this will be relevant later, remember that a confidence interval is a \textbf{two-tailed} procedure, i.e. $k=2$.

<p>



*  Student's t- values are determined using the \texttt{t} family of commands (e.g. \texttt{qt, pt, dt}).
*  To compute quantiles, use the code below.
*  The degrees of freedom must be additionally be specified. Degrees of freedom are computed as sample size minus one ($n-1$)
*  As the degrees of freedom gets larger and larger, the student t distribution converges to the Z distribution.




