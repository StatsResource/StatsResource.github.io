
Testing Model Assumptions {data-navmenu="Inference Procedures"}
==============================================================


Column {.tabset}
----------------------------------

### Testing Procedures

<h5> Testing Procedures</h5>

* <a href="https://youtu.be/R5CI_v66kag"> Exploratory Data Analysis with Minitab Graphical Summaries  </a>.  
* <a href="https://youtu.be/R5CI_v66kag"> Normal Probability (QQ) plots </a>. 
* <a href="https://youtu.be/wXrvg03NSjw"> Anderson Darling Test </a>.
* <a href="https://www.youtube.com/watch?v=vo9DssNQA4E"> The Shapiro-Wilk Test </a>.    

### The Dixon Q test

<h5> The Dixon Q test </h5>

The Dixon Q test is used for identification and rejection of outliers. This assumes normal distribution and per Robert Dean and Wilfrid Dixon, and others, this test should be used sparingly and never more than once in a data set. To apply a Q test for bad data, arrange the data in order of increasing values and calculate Q as defined:

$$ {\displaystyle Q={\frac {\text{gap}}{\text{range}}}} $$

Where gap is the absolute difference between the outlier in question and the closest number to it. If Q > Qtable, where Qtable is a reference value corresponding to the sample size and confidence level, then reject the questionable point. Note that only one point may be rejected from a data set using a Q test. 

<h5> Videos</h5>

* <a href="https://youtu.be/CS_Qgx-IX-8">The Dixon Q Test </a>
* <a href="https://youtu.be/oz1SO-96ByQ">The Dixon Q Test - Worked Example </a>


### The Grubb's Outlier Test

<h5> The Grubb's Outlier Test </h5>


Statisticians have devised several ways to detect outliers. Grubbs' test is particularly easy to follow. This method is also called the ESD method (extreme studentized deviate).

The first step is to quantify how far the outlier is from the others. Calculate the ratio Z as the difference between the outlier and the mean divided by the SD. If Z is large, the value is far from the others. Note that you calculate the mean and SD from all values, including the outlier.

Since 5% of the values in a Gaussian population are more than 1.96 standard deviations from the mean, your first thought might be to conclude that the outlier comes from a different population if Z is greater than 1.96. This approach only works if you know the population mean and SD from other data. Although this is rarely the case in experimental science, it is often the case in quality control. You know the overall mean and SD from historical data, and want to know whether the latest value matches the others. This is the basis for quality control charts.

When analyzing experimental data, you don't know the SD of the population. Instead, you calculate the SD from the data. The presence of an outlier increases the calculated SD. Since the presence of an outlier increases both the numerator (difference between the value and the mean) and denominator (SD of all values), Z does not get very large. In fact, no matter how the data are distributed, Z can not get larger than, where N is the number of values. For example, if N=3, Z cannot be larger than 1.155 for any set of values.

Grubbs and others have tabulated critical values for Z which are tabulated below. The critical value increases with sample size, as expected.

If your calculated value of Z is greater than the critical value in the table, then the P value is less than 0.05. This means that there is less than a $5\%$ chance that you'd encounter an outlier so far from the others (in either direction) by chance alone, if all the data were really sampled from a single Gaussian distribution. Note that the method only works for testing the most extreme value in the sample (if in doubt, calculate Z for all values, but only calculate a P value for Grubbs' test from the largest value of Z.

Once you've identified an outlier, you may choose to exclude that value from your analyses. Or you may choose to keep the outlier, but use robust analysis techniques that do not assume that data are sampled from Gaussian populations.

If you decide to remove the outlier, you then may be tempted to run Grubbs' test again to see if there is a second outlier in your data. If you do this , you cannot use the same table.


###  The Anderson–Darling test

<h5> The Anderson–Darling test </h5>

* The Anderson–Darling test is a statistical test of whether there is evidence that a given sample of data did not arise from a given probability distribution. 
* In its basic form, the test assumes that there are no parameters to be estimated in the distribution being tested, in which case the test and its set of critical values is distribution-free. 
* However, the test is most often used in contexts where a family of distributions is being tested, in which case the parameters of that family need to be estimated and account must be taken of this in adjusting either the test-statistic or its critical values. * When applied to testing if a normal distribution adequately describes a set of data, it is one of the most powerful statistical tools for detecting most departures from normality.
